{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "271db7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\DSC180A-Capstone\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Importing packages\n",
    "from transformers import ViTModel, ViTImageProcessor\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chromadb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "#Import library code\n",
    "import dataloading\n",
    "import model_functions\n",
    "import data_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cad6102",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_csv = \"camera_data/coronado_hills_binary_11-15-2025.csv\"\n",
    "image_dir = \"camera_data/images/\"\n",
    "\n",
    "data = dataloading.get_data(labels_csv=labels_csv, image_dir=image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d6569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = dataloading.get_train_val_test(data = data, output_csvs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1340c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings, train_labels, _, _  = dataloading.load_full_embeddings(train, \"q1_train_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3ad73a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding_dataset = dataloading.CustomEmbeddingDataset(train_embeddings, train_labels)\n",
    "#val_embedding_dataset = dataloading.CustomEmbeddingDataset(embeddings, labels)\n",
    "\n",
    "train_embedding_dataloader = DataLoader(train_embedding_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "#val_embedding_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "225d9db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViTEmbeddingNet(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (pooler): ViTPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "encoder = model_functions.create_encoder()\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c3f824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_state_dict(torch.load('weights/model_weights_camera_11-17-25.pth', weights_only=True))\n",
    "encoder.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a60c97c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationHead(\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_head = model_functions.ClassificationHead()\n",
    "classification_head.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c1326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classification_head.parameters(), lr=1e-4) # Optimize only the new head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e12fb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([32, 768])\n",
      "Embeddings dtype: torch.float32\n",
      "Outputs shape: torch.Size([32, 2])\n",
      "Outputs dtype: torch.float32\n",
      "Has NaN: tensor(True, device='cuda:0')\n",
      "Has Inf: tensor(False, device='cuda:0')\n",
      "Model param dtype: torch.float32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel param dtype:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mnext\u001b[39m(classification_head.parameters()).dtype)\n\u001b[32m     20\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\DSC180A-Capstone\\.venv\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\DSC180A-Capstone\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:340\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    331\u001b[39m inputs = (\n\u001b[32m    332\u001b[39m     (inputs,)\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (torch.Tensor, graph.GradientEdge))\n\u001b[32m   (...)\u001b[39m\u001b[32m    336\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[32m    337\u001b[39m )\n\u001b[32m    339\u001b[39m grad_tensors_ = _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m grad_tensors_ = \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\DSC180A-Capstone\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:220\u001b[39m, in \u001b[36m_make_grads\u001b[39m\u001b[34m(outputs, grads, is_grads_batched)\u001b[39m\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    218\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, torch.Tensor)\n\u001b[32m    219\u001b[39m         new_grads.append(\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m             \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         )\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    223\u001b[39m     new_grads.append(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    classification_head.train() # Set model to training mode\n",
    "    for batch in train_embedding_dataloader:\n",
    "        embeddings = batch['embeddings'].to(device).float()\n",
    "        labels = batch['labels'].to(device).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = classification_head(embeddings)\n",
    "        print(\"Embeddings shape:\", embeddings.shape)\n",
    "        print(\"Embeddings dtype:\", embeddings.dtype)\n",
    "\n",
    "        print(\"Outputs shape:\", outputs.shape)\n",
    "        print(\"Outputs dtype:\", outputs.dtype)\n",
    "\n",
    "        print(\"Has NaN:\", torch.isnan(outputs).any())\n",
    "        print(\"Has Inf:\", torch.isinf(outputs).any())\n",
    "\n",
    "        print(\"Model param dtype:\", next(classification_head.parameters()).dtype)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaba9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

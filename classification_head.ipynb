{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "271db7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\DSC180A-Capstone\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Importing packages\n",
    "from transformers import ViTModel, ViTImageProcessor\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chromadb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "#Import library code\n",
    "import helper_code.dataloading as dataloading\n",
    "import helper_code.model_functions as model_functions\n",
    "import helper_code.data_vis as data_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cad6102",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_csv = \"camera_data/coronado_hills_binary_11-15-2025.csv\"\n",
    "image_dir = \"camera_data/images/\"\n",
    "\n",
    "data = dataloading.get_data(labels_csv=labels_csv, image_dir=image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d6569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = dataloading.get_train_val_test(data = data, output_csvs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1340c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings, train_labels, _, _  = dataloading.load_full_embeddings(train, \"q1_train_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3ad73a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding_dataset = dataloading.CustomEmbeddingDataset(train_embeddings, train_labels)\n",
    "#val_embedding_dataset = dataloading.CustomEmbeddingDataset(embeddings, labels)\n",
    "\n",
    "train_embedding_dataloader = DataLoader(train_embedding_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "#val_embedding_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "225d9db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "encoder = model_functions.create_encoder()\n",
    "encoder.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c3f824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_state_dict(torch.load('weights/model_weights_camera_11-17-25.pth', weights_only=True))\n",
    "encoder.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a60c97c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationHead(\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=2, bias=True)\n",
       "    (3): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_head = model_functions.ClassificationHead()\n",
    "classification_head.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "096c1326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classification_head.parameters(), lr=1e-4) # Optimize only the new head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e12fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    classification_head.train() # Set model to training mode\n",
    "    for batch in train_embedding_dataloader:\n",
    "        embeddings = batch['embeddings'].to(device).float()\n",
    "        labels = batch['labels'].to(device).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = classification_head(embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaaba9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9223408699035645\n"
     ]
    }
   ],
   "source": [
    "classification_head.eval()\n",
    "\n",
    "acc_sum = 0\n",
    "for batch in train_embedding_dataloader:\n",
    "        embeddings = batch['embeddings'].to(device).float()\n",
    "        labels = batch['labels'].to(device).long()\n",
    "\n",
    "        outputs = classification_head(embeddings)\n",
    "        acc_sum += (torch.argmax(outputs, dim = -1) == labels).int().sum()\n",
    "\n",
    "print(f\"Accuracy: {acc_sum / len(train_embedding_dataloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb535905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9948, 0.0052],\n",
       "        [0.0012, 0.9988],\n",
       "        [0.0011, 0.9989],\n",
       "        ...,\n",
       "        [0.9936, 0.0064],\n",
       "        [0.9932, 0.0068],\n",
       "        [0.9947, 0.0053]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_tensor = torch.Tensor(train_embeddings.to_numpy()).to(device)\n",
    "\n",
    "outputs = classification_head(embeddings_tensor)\n",
    "\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb50c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
